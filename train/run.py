import os
import tensorflow as tf
import pandas as pd
from input import input_fn_builder
from tqdm import tqdm
import sys

flags = tf.flags
FLAGS = flags.FLAGS

# flags.DEFINE_string("output_dir", "model", "The output directory.")
flags.DEFINE_string("assets_dir", "assets", "The assets directory generated by assets.py.")
flags.DEFINE_string("checkpoint_dir", 'ckpt', "The directory for storing model check points.")
flags.DEFINE_string("gs_bert_model_ch_dir", 'gs://berserker/repo/assets/chinese_L-12_H-768_A-12', "A google storage path to unzipped BERT chinese_L-12_H-768_A-12 model.")
flags.DEFINE_string("train_file", "dataset/train_128.tfrecords", "The training file output by dataset.py.")

flags.DEFINE_integer("max_seq_length", 128, "Maximum sequence length.")

flags.DEFINE_bool("do_train", False, "Train the model.")
flags.DEFINE_float("learning_rate", 2e-5, "The learning rate.")
flags.DEFINE_integer("train_steps", 200, "Number of training steps.")
flags.DEFINE_float("warmup_proportion", 0.1, "")
flags.DEFINE_integer("save_checkpoints_steps", 800, "Number of steps to save a checkpoint.")
flags.DEFINE_integer("batch_size", 64, "The training and validation batch size.")

flags.DEFINE_bool("do_eval", False, "Evaluate the model.")
flags.DEFINE_string("eval_file", "dataset/val_128.tfrecords", "The validation file output by dataset.py.")
flags.DEFINE_integer("eval_steps", 50, "Number of validation steps.")

flags.DEFINE_bool("do_predict", False, "Make prediction.")
flags.DEFINE_string("predict_file", "dataset/test_128.tfrecords", "The test file output by dataset.py.")

flags.DEFINE_bool("use_tpu", True, "Use TPU for training.")
flags.DEFINE_integer("num_tpu_cores", 8, "The number of TPU cores.")
flags.DEFINE_string("tpu_name", None, "TPU worker.")

def main(_):
    tf.logging.set_verbosity(tf.logging.INFO)
    # tf.gfile.MakeDirs(FLAGS.output_dir)

    sys.path += [os.path.join(FLAGS.assets_dir, 'bert')]
    from model import model_fn_builder
    import modeling

    model_fn = model_fn_builder(
        bert_config=modeling.BertConfig.from_json_file(
            os.path.join(FLAGS.gs_bert_model_ch_dir, 'bert_config.json')
        ),
        init_checkpoint=os.path.join(FLAGS.gs_bert_model_ch_dir, 'bert_model.ckpt'),
        use_tpu=FLAGS.use_tpu,
        use_one_hot_embeddings=True if FLAGS.use_tpu else False,
        learning_rate=FLAGS.learning_rate,
        num_train_steps=FLAGS.train_steps,
        num_warmup_steps=int(FLAGS.train_steps * FLAGS.warmup_proportion)
    )

    run_config = tf.contrib.tpu.RunConfig(
        cluster=tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu_name) if FLAGS.use_tpu else None,
        model_dir=FLAGS.checkpoint_dir,
        save_checkpoints_steps=FLAGS.train_steps,
        tpu_config=tf.contrib.tpu.TPUConfig(
            iterations_per_loop=FLAGS.train_steps,
            num_shards=FLAGS.num_tpu_cores,
            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2
        )
    )

    estimator = tf.contrib.tpu.TPUEstimator(
        use_tpu=FLAGS.use_tpu,
        model_fn=model_fn,
        config=run_config,
        train_batch_size=FLAGS.batch_size,
        eval_batch_size=FLAGS.batch_size,
        predict_batch_size=FLAGS.batch_size
    )

    tf.logging.info('Setup success...')

    if FLAGS.do_train:
        estimator.train(
            input_fn=input_fn_builder(
                input_file=FLAGS.train_file,
                seq_length=FLAGS.max_seq_length,
                shuffle=True,
                repeat=True,
                drop_remainder=FLAGS.use_tpu
            ),
            steps=FLAGS.train_steps,
        )

    if FLAGS.do_eval:
        estimator.evaluate(
            input_fn=input_fn_builder(
                input_file=FLAGS.eval_file,
                seq_length=FLAGS.max_seq_length,
                shuffle=False,
                repeat=False,
                drop_remainder=FLAGS.use_tpu
            ),
            steps=FLAGS.eval_steps,
        )

    if FLAGS.do_predict:
        estimator.predict(
            input_fn=input_fn_builder(
                input_file=FLAGS.predict_file,
                seq_length=FLAGS.max_seq_length,
                shuffle=False,
                repeat=False,
                drop_remainder=FLAGS.use_tpu
            )
        )


if __name__ == "__main__":
  tf.app.run()
